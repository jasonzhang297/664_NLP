{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Week 1\n",
    "\n",
    "## Task 1: play with python: basics\n",
    "\n",
    "1+2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mei’s lab'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str=\"Mei\"\n",
    "str1=\"’s lab\"\n",
    "str+str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Task 2: download/import nltk \n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> ALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Error loading ALL: Package 'ALL' not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> H\n",
      "\n",
      "Commands:\n",
      "  d) Download a package or collection     u) Update out of date packages\n",
      "  l) List packages & collections          h) Help\n",
      "  c) View & Modify Configuration          q) Quit\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> D\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> l\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: \n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] dolch............... Dolch Word List\n",
      "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] framenet_v17........ FrameNet 1.7\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n",
      "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
      "Hit Enter to continue: \n",
      "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
      "                           for parser comparison\n",
      "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
      "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
      "                           part-of-speech tags\n",
      "  [ ] machado............. Machado de Assis -- Obra Completa\n",
      "  [ ] masc_tagged......... MASC Tagged Corpus\n",
      "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
      "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
      "  [ ] moses_sample........ Moses Sample Models\n",
      "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
      "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
      "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
      "                           2015) subset of the Paraphrase Database.\n",
      "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
      "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
      "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
      "  [ ] nps_chat............ NPS Chat\n",
      "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
      "  [ ] omw................. Open Multilingual Wordnet\n",
      "  [ ] opinion_lexicon..... Opinion Lexicon\n",
      "Hit Enter to continue: \n",
      "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
      "  [ ] paradigms........... Paradigm Corpus\n",
      "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
      "                           Evaluation Shared Task\n",
      "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
      "                           character properties in Perl\n",
      "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
      "  [ ] pl196x.............. Polish language of the XX century sixties\n",
      "  [ ] porter_test......... Porter Stemmer Test Files\n",
      "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
      "  [ ] problem_reports..... Problem Report Corpus\n",
      "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
      "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
      "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
      "  [ ] pros_cons........... Pros and Cons\n",
      "  [ ] ptb................. Penn Treebank\n",
      "  [ ] punkt............... Punkt Tokenizer Models\n",
      "  [ ] qc.................. Experimental Data for Question Classification\n",
      "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
      "                           version\n",
      "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
      "                           Portuguesa)\n",
      "Hit Enter to continue: \n",
      "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
      "  [ ] sample_grammars..... Sample Grammars\n",
      "  [ ] semcor.............. SemCor 3.0\n",
      "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
      "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
      "  [ ] sentiwordnet........ SentiWordNet\n",
      "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
      "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
      "  [ ] smultron............ SMULTRON Corpus Sample\n",
      "  [ ] snowball_data....... Snowball Data\n",
      "  [ ] spanish_grammars.... Grammars for Spanish\n",
      "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
      "  [ ] stopwords........... Stopwords Corpus\n",
      "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
      "  [ ] swadesh............. Swadesh Wordlists\n",
      "  [ ] switchboard......... Switchboard Corpus Sample\n",
      "  [ ] tagsets............. Help on Tagsets\n",
      "  [ ] timit............... TIMIT Corpus Sample\n",
      "  [ ] toolbox............. Toolbox Sample Files\n",
      "  [ ] treebank............ Penn Treebank Sample\n",
      "  [ ] twitter_samples..... Twitter Samples\n",
      "Hit Enter to continue: \n",
      "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
      "                           (Unicode Version)\n",
      "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
      "  [ ] unicode_samples..... Unicode Samples\n",
      "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
      "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
      "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
      "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
      "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
      "  [ ] webtext............. Web Text Corpus\n",
      "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
      "  [ ] word2vec_sample..... Word2Vec Sample\n",
      "  [ ] wordnet2021......... Open English Wordnet 2021\n",
      "  [ ] wordnet31........... Wordnet 3.1\n",
      "  [ ] wordnet............. WordNet\n",
      "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
      "  [ ] words............... Word Lists\n",
      "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
      "                           English Prose\n",
      "\n",
      "Collections:\n",
      "  [ ] all-corpora......... All the corpora\n",
      "Hit Enter to continue: \n",
      "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
      "                           branch\n",
      "  [ ] all................. All packages\n",
      "  [ ] book................ Everything used in the NLTK Book\n",
      "  [ ] popular............. Popular packages\n",
      "  [ ] tests............... Packages for running tests\n",
      "  [ ] third-party......... Third-party data packages\n",
      "\n",
      "([*] marks installed packages)\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Identifier> l\n",
      "Packages:\n",
      "  [ ] abc................. Australian Broadcasting Commission 2006\n",
      "  [ ] alpino.............. Alpino Dutch Treebank\n",
      "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
      "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
      "  [ ] basque_grammars..... Grammars for Basque\n",
      "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
      "                           Extraction Systems in Biology)\n",
      "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
      "  [ ] book_grammars....... Grammars from NLTK Book\n",
      "  [ ] brown............... Brown Corpus\n",
      "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
      "  [ ] cess_cat............ CESS-CAT Treebank\n",
      "  [ ] cess_esp............ CESS-ESP Treebank\n",
      "  [ ] chat80.............. Chat-80 Data Files\n",
      "  [ ] city_database....... City Database\n",
      "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
      "  [ ] comparative_sentences Comparative Sentence Dataset\n",
      "  [ ] comtrans............ ComTrans Corpus Sample\n",
      "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
      "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
      "Hit Enter to continue: \n",
      "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
      "                           and Basque Subset)\n",
      "  [ ] crubadan............ Crubadan Corpus\n",
      "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
      "  [ ] dolch............... Dolch Word List\n",
      "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
      "                           Corpus\n",
      "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
      "  [ ] floresta............ Portuguese Treebank\n",
      "  [ ] framenet_v15........ FrameNet 1.5\n",
      "  [ ] framenet_v17........ FrameNet 1.7\n",
      "  [ ] gazetteers.......... Gazeteer Lists\n",
      "  [ ] genesis............. Genesis Corpus\n",
      "  [ ] gutenberg........... Project Gutenberg Selections\n",
      "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
      "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
      "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
      "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
      "                           ChaSen format)\n",
      "  [ ] kimmo............... PC-KIMMO Data Files\n",
      "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
      "Hit Enter to continue: \n",
      "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
      "                           for parser comparison\n",
      "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
      "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
      "                           part-of-speech tags\n",
      "  [ ] machado............. Machado de Assis -- Obra Completa\n",
      "  [ ] masc_tagged......... MASC Tagged Corpus\n",
      "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
      "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
      "  [ ] moses_sample........ Moses Sample Models\n",
      "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
      "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
      "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
      "                           2015) subset of the Paraphrase Database.\n",
      "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
      "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
      "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
      "  [ ] nps_chat............ NPS Chat\n",
      "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
      "  [ ] omw................. Open Multilingual Wordnet\n",
      "  [ ] opinion_lexicon..... Opinion Lexicon\n",
      "Hit Enter to continue: \n",
      "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
      "  [ ] paradigms........... Paradigm Corpus\n",
      "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
      "                           Evaluation Shared Task\n",
      "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
      "                           character properties in Perl\n",
      "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
      "  [ ] pl196x.............. Polish language of the XX century sixties\n",
      "  [ ] porter_test......... Porter Stemmer Test Files\n",
      "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
      "  [ ] problem_reports..... Problem Report Corpus\n",
      "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
      "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
      "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
      "  [ ] pros_cons........... Pros and Cons\n",
      "  [ ] ptb................. Penn Treebank\n",
      "  [ ] punkt............... Punkt Tokenizer Models\n",
      "  [ ] qc.................. Experimental Data for Question Classification\n",
      "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
      "                           version\n",
      "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
      "                           Portuguesa)\n",
      "Hit Enter to continue: \n",
      "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
      "  [ ] sample_grammars..... Sample Grammars\n",
      "  [ ] semcor.............. SemCor 3.0\n",
      "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
      "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
      "  [ ] sentiwordnet........ SentiWordNet\n",
      "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
      "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
      "  [ ] smultron............ SMULTRON Corpus Sample\n",
      "  [ ] snowball_data....... Snowball Data\n",
      "  [ ] spanish_grammars.... Grammars for Spanish\n",
      "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
      "  [ ] stopwords........... Stopwords Corpus\n",
      "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
      "  [ ] swadesh............. Swadesh Wordlists\n",
      "  [ ] switchboard......... Switchboard Corpus Sample\n",
      "  [ ] tagsets............. Help on Tagsets\n",
      "  [ ] timit............... TIMIT Corpus Sample\n",
      "  [ ] toolbox............. Toolbox Sample Files\n",
      "  [ ] treebank............ Penn Treebank Sample\n",
      "  [ ] twitter_samples..... Twitter Samples\n",
      "Hit Enter to continue: \n",
      "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
      "                           (Unicode Version)\n",
      "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
      "  [ ] unicode_samples..... Unicode Samples\n",
      "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
      "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
      "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
      "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
      "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
      "  [ ] webtext............. Web Text Corpus\n",
      "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
      "  [ ] word2vec_sample..... Word2Vec Sample\n",
      "  [ ] wordnet2021......... Open English Wordnet 2021\n",
      "  [ ] wordnet31........... Wordnet 3.1\n",
      "  [ ] wordnet............. WordNet\n",
      "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
      "  [ ] words............... Word Lists\n",
      "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
      "                           English Prose\n",
      "\n",
      "Collections:\n",
      "  [ ] all-corpora......... All the corpora\n",
      "Hit Enter to continue: \n",
      "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
      "                           branch\n",
      "  [ ] all................. All packages\n",
      "  [ ] book................ Everything used in the NLTK Book\n",
      "  [ ] popular............. Popular packages\n",
      "  [ ] tests............... Packages for running tests\n",
      "  [ ] third-party......... Third-party data packages\n",
      "\n",
      "([*] marks installed packages)\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> ALL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Error loading ALL: Package 'ALL' not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Downloading collection 'all'\n",
      "       | \n",
      "       | Downloading package abc to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/abc.zip.\n",
      "       | Downloading package alpino to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/alpino.zip.\n",
      "       | Downloading package averaged_perceptron_tagger to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "       | Downloading package averaged_perceptron_tagger_ru to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
      "       | Downloading package basque_grammars to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping grammars/basque_grammars.zip.\n",
      "       | Downloading package biocreative_ppi to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/biocreative_ppi.zip.\n",
      "       | Downloading package bllip_wsj_no_aux to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "       | Downloading package book_grammars to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping grammars/book_grammars.zip.\n",
      "       | Downloading package brown to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/brown.zip.\n",
      "       | Downloading package brown_tei to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/brown_tei.zip.\n",
      "       | Downloading package cess_cat to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/cess_cat.zip.\n",
      "       | Downloading package cess_esp to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/cess_esp.zip.\n",
      "       | Downloading package chat80 to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/chat80.zip.\n",
      "       | Downloading package city_database to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/city_database.zip.\n",
      "       | Downloading package cmudict to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/cmudict.zip.\n",
      "       | Downloading package comparative_sentences to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/comparative_sentences.zip.\n",
      "       | Downloading package comtrans to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package conll2000 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/conll2000.zip.\n",
      "       | Downloading package conll2002 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/conll2002.zip.\n",
      "       | Downloading package conll2007 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package crubadan to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/crubadan.zip.\n",
      "       | Downloading package dependency_treebank to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/dependency_treebank.zip.\n",
      "       | Downloading package dolch to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/dolch.zip.\n",
      "       | Downloading package europarl_raw to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/europarl_raw.zip.\n",
      "       | Downloading package extended_omw to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package floresta to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/floresta.zip.\n",
      "       | Downloading package framenet_v15 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v15.zip.\n",
      "       | Downloading package framenet_v17 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v17.zip.\n",
      "       | Downloading package gazetteers to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/gazetteers.zip.\n",
      "       | Downloading package genesis to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/genesis.zip.\n",
      "       | Downloading package gutenberg to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/gutenberg.zip.\n",
      "       | Downloading package ieer to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/ieer.zip.\n",
      "       | Downloading package inaugural to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/inaugural.zip.\n",
      "       | Downloading package indian to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/indian.zip.\n",
      "       | Downloading package jeita to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package kimmo to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/kimmo.zip.\n",
      "       | Downloading package knbc to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package large_grammars to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping grammars/large_grammars.zip.\n",
      "       | Downloading package lin_thesaurus to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/lin_thesaurus.zip.\n",
      "       | Downloading package mac_morpho to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/mac_morpho.zip.\n",
      "       | Downloading package machado to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package masc_tagged to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package maxent_ne_chunker to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "       | Downloading package maxent_treebank_pos_tagger to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "       | Downloading package moses_sample to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping models/moses_sample.zip.\n",
      "       | Downloading package movie_reviews to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/movie_reviews.zip.\n",
      "       | Downloading package mte_teip5 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/mte_teip5.zip.\n",
      "       | Downloading package mwa_ppdb to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping misc/mwa_ppdb.zip.\n",
      "       | Downloading package names to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/names.zip.\n",
      "       | Downloading package nombank.1.0 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package nonbreaking_prefixes to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "       | Downloading package nps_chat to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/nps_chat.zip.\n",
      "       | Downloading package omw to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package omw-1.4 to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package opinion_lexicon to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/opinion_lexicon.zip.\n",
      "       | Downloading package panlex_swadesh to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package paradigms to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/paradigms.zip.\n",
      "       | Downloading package pe08 to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/pe08.zip.\n",
      "       | Downloading package perluniprops to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping misc/perluniprops.zip.\n",
      "       | Downloading package pil to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/pil.zip.\n",
      "       | Downloading package pl196x to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/pl196x.zip.\n",
      "       | Downloading package porter_test to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping stemmers/porter_test.zip.\n",
      "       | Downloading package ppattach to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/ppattach.zip.\n",
      "       | Downloading package problem_reports to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/problem_reports.zip.\n",
      "       | Downloading package product_reviews_1 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_1.zip.\n",
      "       | Downloading package product_reviews_2 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_2.zip.\n",
      "       | Downloading package propbank to\n",
      "       |     /Users/jasonzhang/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       | Downloading package pros_cons to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/pros_cons.zip.\n",
      "       | Downloading package ptb to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/ptb.zip.\n",
      "       | Downloading package punkt to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping tokenizers/punkt.zip.\n",
      "       | Downloading package qc to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/qc.zip.\n",
      "       | Downloading package reuters to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package rslp to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping stemmers/rslp.zip.\n",
      "       | Downloading package rte to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/rte.zip.\n",
      "       | Downloading package sample_grammars to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping grammars/sample_grammars.zip.\n",
      "       | Downloading package semcor to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package senseval to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/senseval.zip.\n",
      "       | Downloading package sentence_polarity to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/sentence_polarity.zip.\n",
      "       | Downloading package sentiwordnet to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/sentiwordnet.zip.\n",
      "       | Downloading package shakespeare to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/shakespeare.zip.\n",
      "       | Downloading package sinica_treebank to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/sinica_treebank.zip.\n",
      "       | Downloading package smultron to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/smultron.zip.\n",
      "       | Downloading package snowball_data to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package spanish_grammars to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping grammars/spanish_grammars.zip.\n",
      "       | Downloading package state_union to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/state_union.zip.\n",
      "       | Downloading package stopwords to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/stopwords.zip.\n",
      "       | Downloading package subjectivity to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/subjectivity.zip.\n",
      "       | Downloading package swadesh to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/swadesh.zip.\n",
      "       | Downloading package switchboard to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/switchboard.zip.\n",
      "       | Downloading package tagsets to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping help/tagsets.zip.\n",
      "       | Downloading package timit to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/timit.zip.\n",
      "       | Downloading package toolbox to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/toolbox.zip.\n",
      "       | Downloading package treebank to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/treebank.zip.\n",
      "       | Downloading package twitter_samples to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/twitter_samples.zip.\n",
      "       | Downloading package udhr to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/udhr.zip.\n",
      "       | Downloading package udhr2 to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/udhr2.zip.\n",
      "       | Downloading package unicode_samples to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/unicode_samples.zip.\n",
      "       | Downloading package universal_tagset to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping taggers/universal_tagset.zip.\n",
      "       | Downloading package universal_treebanks_v20 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package vader_lexicon to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package verbnet to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/verbnet.zip.\n",
      "       | Downloading package verbnet3 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/verbnet3.zip.\n",
      "       | Downloading package webtext to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/webtext.zip.\n",
      "       | Downloading package wmt15_eval to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping models/wmt15_eval.zip.\n",
      "       | Downloading package word2vec_sample to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping models/word2vec_sample.zip.\n",
      "       | Downloading package wordnet to /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package wordnet2021 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package wordnet31 to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       | Downloading package wordnet_ic to\n",
      "       |     /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/wordnet_ic.zip.\n",
      "       | Downloading package words to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/words.zip.\n",
      "       | Downloading package ycoe to /Users/jasonzhang/nltk_data...\n",
      "       |   Unzipping corpora/ycoe.zip.\n",
      "       | \n",
      "     Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if your computer has not installed nltk yet, you need to download it\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the “book” collection in nltk\n",
    "from nltk.book import *\n",
    "# type predefined variables\n",
    "# sent1 is a list\n",
    "sent1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ishmael'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the third item in list sent1\n",
    "sent1[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msent1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent1[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text1 is a text from Moby Dick\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Moby', 'Dick', 'by']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[0:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Moby', 'Dick', 'by', 'Herman']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the first five items in text1\n",
    "text1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and',\n",
       " 'grammars',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'queer',\n",
       " 'handkerchief',\n",
       " ',',\n",
       " 'mockingly',\n",
       " 'embellished']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[45:59]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'he', 'was', 'put', 'in', 'a', 'coffin', 'in', 'Egypt', '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first/last 10 words in text3\n",
    "text3[-10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"str\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# try to add one string variable to a list variable\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43msent1\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "# try to add one string variable to a list variable\n",
    "sent1+str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "## Task 3:searching text \n",
    "# searching text by using “concordance”\n",
    "text1.concordance('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 79 matches:\n",
      ", however , and , as a mark of his affection for the three girls , he left them\n",
      "t . It was very well known that no affection was ever supposed to exist between\n",
      "deration of politeness or maternal affection on the side of the former , the tw\n",
      "d the suspicion -- the hope of his affection for me may warrant , without impru\n",
      "hich forbade the indulgence of his affection . She knew that his mother neither\n",
      "rd she gave one with still greater affection . Though her late conversation wit\n",
      " can never hope to feel or inspire affection again , and if her home be uncomfo\n",
      "m of the sense , elegance , mutual affection , and domestic comfort of the fami\n",
      ", and which recommended him to her affection beyond every thing else . His soci\n",
      "ween the parties might forward the affection of Mr . Willoughby , an equally st\n",
      " the most pointed assurance of her affection . Elinor could not be surprised at\n",
      "he natural consequence of a strong affection in a young and ardent mind . This \n",
      " opinion . But by an appeal to her affection for her mother , by representing t\n",
      " every alteration of a place which affection had established as perfect with hi\n",
      "e will always have one claim of my affection , which no other can possibly shar\n",
      "f the evening declared at once his affection and happiness . \" Shall we see you\n",
      "ause he took leave of us with less affection than his usual behaviour has shewn\n",
      "ness .\" \" I want no proof of their affection ,\" said Elinor ; \" but of their en\n",
      "onths , without telling her of his affection ;-- that they should part without \n",
      "ould be the natural result of your affection for her . She used to be all unres\n",
      "distinguished Elinor by no mark of affection . Marianne saw and listened with i\n",
      "th no inclination for expense , no affection for strangers , no profession , an\n",
      "till distinguished her by the same affection which once she had felt no doubt o\n",
      "al of her confidence in Edward ' s affection , to the remembrance of every mark\n",
      " was made ? Had he never owned his affection to yourself ?\" \" Oh , no ; but if \n"
     ]
    }
   ],
   "source": [
    "text2.concordance('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "# find similar words in text1\n",
    "text1.similar('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_and\n"
     ]
    }
   ],
   "source": [
    "# why \"monstrous\" is similar to \"delightfully\"? \n",
    "text1.common_contexts([\"monstrous\", \"delightfully\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Task 4: counting vocabulary\n",
    "# how many tokens are in text3?\n",
    "len(text3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## if we want to find out the # of unique tokens\n",
    "len(set(text3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorting tokens alphabetically\n",
    "sorted(set(text3))[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate lexical richness\n",
    "len(set(text3))/len(text3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4475918148512197"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting occurrence and percentage of ‘he’ in text3\n",
    "text3.count(\"he\")\n",
    "100 * text3.count(\"he\")/len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADDITIONAL',\n",
       " 'ADVANCING',\n",
       " 'ADVENTURES',\n",
       " 'AFFGHANISTAN',\n",
       " 'APPLICATION',\n",
       " 'APPROACHING',\n",
       " 'ASCENDING',\n",
       " 'ATTITUDES',\n",
       " 'Abominable',\n",
       " 'Accessory',\n",
       " 'According',\n",
       " 'Accordingly',\n",
       " 'Advancement',\n",
       " 'Adventures',\n",
       " 'Affidavit',\n",
       " 'Affrighted',\n",
       " 'Afterwards',\n",
       " 'Ahasuerus',\n",
       " 'Albatross',\n",
       " 'Albemarle',\n",
       " 'Aldrovandi',\n",
       " 'Aldrovandus',\n",
       " 'Alexander',\n",
       " 'Alexanders',\n",
       " 'Alleghanian',\n",
       " 'Alleghanies',\n",
       " 'Ambergriese',\n",
       " 'Ambergris',\n",
       " 'Americans',\n",
       " 'Amsterdam',\n",
       " 'Anacharsis',\n",
       " 'Anatomist',\n",
       " 'Andromeda',\n",
       " 'Anomalous',\n",
       " 'Antarctic',\n",
       " 'Antiochus',\n",
       " 'Archbishop',\n",
       " 'Archipelagoes',\n",
       " 'Aristotle',\n",
       " 'Aroostook',\n",
       " 'Arsacidean',\n",
       " 'Arsacides',\n",
       " 'Asphaltites',\n",
       " 'Assaulted',\n",
       " 'Assuredly',\n",
       " 'Astronomy',\n",
       " 'Atlantics',\n",
       " 'Australia',\n",
       " 'Australian',\n",
       " 'BIOGRAPHY',\n",
       " 'BLACKSMITH',\n",
       " 'BLACKSTONE',\n",
       " 'BREAKWATER',\n",
       " 'Babylonian',\n",
       " 'Baltimore',\n",
       " 'Bartholomew',\n",
       " 'Basilosaurus',\n",
       " 'Battering',\n",
       " 'Beelzebub',\n",
       " 'Belisarius',\n",
       " 'Belshazzar',\n",
       " 'Bendigoes',\n",
       " 'Berkshire',\n",
       " 'Bibliographical',\n",
       " 'Biographical',\n",
       " 'Blacksmith',\n",
       " 'Blackstone',\n",
       " 'Blocksburg',\n",
       " 'Bonapartes',\n",
       " 'Bonneterre',\n",
       " 'Brandreth',\n",
       " 'Breakfast',\n",
       " 'Brighggians',\n",
       " 'Bulkington',\n",
       " 'CARPENTER',\n",
       " 'CHRONICLER',\n",
       " 'CIRCUMNAVIGATION',\n",
       " 'COMMERCIAL',\n",
       " 'COMMODORE',\n",
       " 'CONTESTED',\n",
       " 'CONTINUES',\n",
       " 'CONVERSATIONS',\n",
       " 'Caesarian',\n",
       " 'Californian',\n",
       " 'Canallers',\n",
       " 'Cannibals',\n",
       " 'Canterbury',\n",
       " 'Capricornus',\n",
       " 'Carefully',\n",
       " 'Carpenter',\n",
       " 'Cathedral',\n",
       " 'Certainly',\n",
       " 'Cervantes',\n",
       " 'Champagne',\n",
       " 'Champollion',\n",
       " 'Charlemagne',\n",
       " 'Chartering',\n",
       " 'Christendom',\n",
       " 'Christian',\n",
       " 'Christianity',\n",
       " 'Christians',\n",
       " 'Christmas',\n",
       " 'Circassian',\n",
       " 'Circumambulate',\n",
       " 'Cleopatra',\n",
       " 'Cleveland',\n",
       " 'Coleridge',\n",
       " 'Commanded',\n",
       " 'Commanders',\n",
       " 'Commodore',\n",
       " 'Commodores',\n",
       " 'Commonwealth',\n",
       " 'Companies',\n",
       " 'Comparing',\n",
       " 'Concerning',\n",
       " 'Congregation',\n",
       " 'Congregational',\n",
       " 'Connecticut',\n",
       " 'Consequently',\n",
       " 'Considering',\n",
       " 'Constable',\n",
       " 'Constantine',\n",
       " 'Constantinople',\n",
       " 'Consumptive',\n",
       " 'Continents',\n",
       " 'Contrasted',\n",
       " 'Conversation',\n",
       " 'Convulsively',\n",
       " 'Copenhagen',\n",
       " 'Corinthians',\n",
       " 'Corkscrew',\n",
       " 'Coronation',\n",
       " 'Corresponding',\n",
       " 'Counterpane',\n",
       " 'Cruppered',\n",
       " 'Crusaders',\n",
       " 'DESTROYED',\n",
       " 'DICTIONARY',\n",
       " 'DISCOVERS',\n",
       " 'DISSECTION',\n",
       " 'DUODECIMO',\n",
       " 'DUODECIMOES',\n",
       " 'Dardanelles',\n",
       " 'Darmonodes',\n",
       " 'Decapitation',\n",
       " 'Deliberately',\n",
       " 'Delightful',\n",
       " 'Deliverer',\n",
       " 'Descartian',\n",
       " 'Descending',\n",
       " 'Desecrated',\n",
       " 'Desmarest',\n",
       " 'Desolation',\n",
       " 'Despairing',\n",
       " 'Deuteronomy',\n",
       " 'Discovery',\n",
       " 'Dorchester',\n",
       " 'Doubtless',\n",
       " 'Dunfermline',\n",
       " 'Duodecimo',\n",
       " 'Duodecimoes',\n",
       " 'ECKERMANN',\n",
       " 'ELIZABETH',\n",
       " 'EMBONPOINT',\n",
       " 'ERROMANGOAN',\n",
       " 'ETYMOLOGY',\n",
       " 'EXCHANGING',\n",
       " 'EXTENDING',\n",
       " 'Earthsman',\n",
       " 'Ecclesiastes',\n",
       " 'Eddystone',\n",
       " 'Egyptians',\n",
       " 'Ehrenbreitstein',\n",
       " 'Elephanta',\n",
       " 'Elephants',\n",
       " 'Ellenborough',\n",
       " 'Elsewhere',\n",
       " 'Emblazonings',\n",
       " 'Emboldened',\n",
       " 'Enderbies',\n",
       " 'Englander',\n",
       " 'Englishman',\n",
       " 'Englishmen',\n",
       " 'Entreaties',\n",
       " 'Enveloped',\n",
       " 'Equatorial',\n",
       " 'Erromanggoans',\n",
       " 'Erroneous',\n",
       " 'Esquimaux',\n",
       " 'Eternities',\n",
       " 'Ethiopian',\n",
       " 'Euclidean',\n",
       " 'Euroclydon',\n",
       " 'Evangelist',\n",
       " 'Evangelists',\n",
       " 'Excellent',\n",
       " 'Excepting',\n",
       " 'Exception',\n",
       " 'Expedition',\n",
       " 'Expeditions',\n",
       " 'Exploring',\n",
       " 'Extending',\n",
       " 'FISHERMAN',\n",
       " 'FOLLOWING',\n",
       " 'FORECASTLE',\n",
       " 'FREDERICK',\n",
       " 'Falsehood',\n",
       " 'Fashioned',\n",
       " 'Feegeeans',\n",
       " 'Ferdinando',\n",
       " 'Fernandes',\n",
       " 'Fisheries',\n",
       " 'Floundered',\n",
       " 'Flounders',\n",
       " 'Forecastle',\n",
       " 'Forthwith',\n",
       " 'Frankfort',\n",
       " 'Frederick',\n",
       " 'Frenchman',\n",
       " 'Frenchmen',\n",
       " 'Friesland',\n",
       " 'Frobisher',\n",
       " 'Froissart',\n",
       " 'Furthermore',\n",
       " 'GENERALLY',\n",
       " 'GOLDSMITH',\n",
       " 'GONDIBERT',\n",
       " 'GREENLAND',\n",
       " 'Galleries',\n",
       " 'Gallipagos',\n",
       " 'Gentlemen',\n",
       " 'Geological',\n",
       " 'Gibraltar',\n",
       " 'Goldsmith',\n",
       " 'Greenland',\n",
       " 'Greenlanders',\n",
       " 'Greenlandmen',\n",
       " 'Greenwich',\n",
       " 'Grenadier',\n",
       " 'Growlands',\n",
       " 'Guernseyman',\n",
       " 'HARPOONEERS',\n",
       " 'HAWTHORNE',\n",
       " 'HEREABOUTS',\n",
       " 'HORIZONTAL',\n",
       " 'Hampshire',\n",
       " 'Hanoverian',\n",
       " 'Hardicanutes',\n",
       " 'Harmattans',\n",
       " 'Harpooneer',\n",
       " 'Hearkening',\n",
       " 'Heidelburgh',\n",
       " 'Herculaneum',\n",
       " 'Himmalehan',\n",
       " 'Himmalehs',\n",
       " 'Hindostan',\n",
       " 'Historians',\n",
       " 'Historically',\n",
       " 'Hogarthian',\n",
       " 'Hollanders',\n",
       " 'Holofernes',\n",
       " 'Honourary',\n",
       " 'Hosmannus',\n",
       " 'Hoveringly',\n",
       " 'Humiliation',\n",
       " 'Hurriedly',\n",
       " 'Hyperborean',\n",
       " 'ICELANDIC',\n",
       " 'ISOLATOES',\n",
       " 'Icelandic',\n",
       " 'Ignorance',\n",
       " 'Immediately',\n",
       " 'Immemorial',\n",
       " 'Impenetrable',\n",
       " 'Impossible',\n",
       " 'Improving',\n",
       " 'Indolence',\n",
       " 'Inferable',\n",
       " 'Inlanders',\n",
       " 'Innkeeper',\n",
       " 'Innocents',\n",
       " 'Inquisition',\n",
       " 'Inserting',\n",
       " 'Instances',\n",
       " 'Instantly',\n",
       " 'Insufferable',\n",
       " 'Insurance',\n",
       " 'Interweaving',\n",
       " 'Intolerably',\n",
       " 'Invisible',\n",
       " 'Islanders',\n",
       " 'Isolatoes',\n",
       " 'Israelites',\n",
       " 'JEFFERSON',\n",
       " 'Justinian',\n",
       " 'Kentuckian',\n",
       " 'Krusenstern',\n",
       " 'Krusensterns',\n",
       " 'LENGTHWISE',\n",
       " 'LEVIATHAN',\n",
       " 'LIGHTNING',\n",
       " 'Langsdorff',\n",
       " 'Laplander',\n",
       " 'Laplandish',\n",
       " 'Leicester',\n",
       " 'Leuwenhoeck',\n",
       " 'Levelling',\n",
       " 'Leviathan',\n",
       " 'Leviathanic',\n",
       " 'Leviathanism',\n",
       " 'Leviathans',\n",
       " 'Liberties',\n",
       " 'Librarian',\n",
       " 'Lieutenant',\n",
       " 'Lightning',\n",
       " 'Literally',\n",
       " 'Littleton',\n",
       " 'Louisiana',\n",
       " 'Loveliness',\n",
       " 'MCCULLOCH',\n",
       " 'MIRABILIS',\n",
       " 'MISSIONARY',\n",
       " 'MONTAIGNE',\n",
       " 'MONTGOMERY',\n",
       " 'MYSTERIOUS',\n",
       " 'Maccabees',\n",
       " 'Macrocephalus',\n",
       " 'Maelstrom',\n",
       " 'Magnanimous',\n",
       " 'Magnitude',\n",
       " 'Manchester',\n",
       " 'Manhattoes',\n",
       " 'Massachusetts',\n",
       " 'Meanwhile',\n",
       " 'Measurement',\n",
       " 'Mediterranean',\n",
       " 'Melancthon',\n",
       " 'Mephistophelean',\n",
       " 'Mesopotamian',\n",
       " 'Methuselah',\n",
       " 'Midwifery',\n",
       " 'Miserable',\n",
       " 'Mississippi',\n",
       " 'Mississippies',\n",
       " 'Mogulship',\n",
       " 'Monadnock',\n",
       " 'Monongahela',\n",
       " 'Monsieurs',\n",
       " 'Monstrous',\n",
       " 'Mountains',\n",
       " 'Mysteriously',\n",
       " 'Mysticetus',\n",
       " 'NANTUCKET',\n",
       " 'NARRATIVE',\n",
       " 'NATURALIST',\n",
       " 'NEWSPAPER',\n",
       " 'Nantucket',\n",
       " 'Nantucketer',\n",
       " 'Nantucketers',\n",
       " 'Nantuckois',\n",
       " 'Narcissus',\n",
       " 'Narragansett',\n",
       " 'Neskyeuna',\n",
       " 'Netherlands',\n",
       " 'Nevertheless',\n",
       " 'Newcastle',\n",
       " 'Newfoundland',\n",
       " 'Nightgown',\n",
       " 'Norwegian',\n",
       " 'Observatory',\n",
       " 'Ordinaire',\n",
       " 'Orientals',\n",
       " 'Originally',\n",
       " 'Overhearing',\n",
       " 'PARLIAMENT',\n",
       " 'PORTUGUESE',\n",
       " 'PRESIDENCY',\n",
       " 'Pannangians',\n",
       " 'Pantheistic',\n",
       " 'Pantheists',\n",
       " 'Paracelsan',\n",
       " 'Paracelsus',\n",
       " 'Parisians',\n",
       " 'Parliament',\n",
       " 'Patagonia',\n",
       " 'Patagonian',\n",
       " 'Pedestrians',\n",
       " 'Penetrating',\n",
       " 'Perchance',\n",
       " 'Petrified',\n",
       " 'Philippine',\n",
       " 'Philistine',\n",
       " 'Philistines',\n",
       " 'Philologically',\n",
       " 'Philopater',\n",
       " 'Phrenologist',\n",
       " 'Physiognomically',\n",
       " 'Physiognomist',\n",
       " 'Physiognomy',\n",
       " 'Pirohitee',\n",
       " 'Pitchpoling',\n",
       " 'Pitferren',\n",
       " 'Platonian',\n",
       " 'Platonist',\n",
       " 'Platonists',\n",
       " 'Polynesia',\n",
       " 'Polynesian',\n",
       " 'Polynesians',\n",
       " 'Pontoppodan',\n",
       " 'Porpoises',\n",
       " 'Portuguese',\n",
       " 'Possession',\n",
       " 'Postscript',\n",
       " 'Pottowottamie',\n",
       " 'Pottsfich',\n",
       " 'Praetorians',\n",
       " 'Presbyterian',\n",
       " 'Presbyterians',\n",
       " 'Presently',\n",
       " 'Preserving',\n",
       " 'Preternatural',\n",
       " 'Procopius',\n",
       " 'Prodigies',\n",
       " 'Prodromus',\n",
       " 'Projecting',\n",
       " 'Prometheus',\n",
       " 'Propontis',\n",
       " 'Protestant',\n",
       " 'Providence',\n",
       " 'Puritanic',\n",
       " 'Pythagoras',\n",
       " 'Pythagorean',\n",
       " 'Quakeress',\n",
       " 'Quakerish',\n",
       " 'Quakerism',\n",
       " 'RECLINING',\n",
       " 'REFERENCE',\n",
       " 'REMAINING',\n",
       " 'REPUBLICA',\n",
       " 'RESPECTABLE',\n",
       " 'RICHARDSON',\n",
       " 'Railroads',\n",
       " 'Randolphs',\n",
       " 'Receiving',\n",
       " 'Reckoning',\n",
       " 'Reference',\n",
       " 'Regarding',\n",
       " 'Remembering',\n",
       " 'Rensselaers',\n",
       " 'Republican',\n",
       " 'Respectively',\n",
       " 'Retreating',\n",
       " 'Retribution',\n",
       " 'Returning',\n",
       " 'Righteousness',\n",
       " 'Rinaldini',\n",
       " 'Ripplingly',\n",
       " 'Rondeletius',\n",
       " 'SHIPMATES',\n",
       " 'SHIPWRECK',\n",
       " 'SHRINKING',\n",
       " 'SKRIMSHANDER',\n",
       " 'SOMETHING',\n",
       " 'SOMEWHERE',\n",
       " 'SPERMACETI',\n",
       " 'SPITZBERGEN',\n",
       " 'SPOUTINGS',\n",
       " 'SPRINGING',\n",
       " 'STRAFFORD',\n",
       " 'SURVIVORS',\n",
       " 'Sagittarius',\n",
       " 'Salisbury',\n",
       " 'Scandinavian',\n",
       " 'Schmerenburgh',\n",
       " 'Schoolmasters',\n",
       " 'Scriptural',\n",
       " 'Scripture',\n",
       " 'Scriptures',\n",
       " 'Sebastian',\n",
       " 'Secretary',\n",
       " 'Semiramis',\n",
       " 'Seychelle',\n",
       " 'Shakespeare',\n",
       " 'Sheffield',\n",
       " 'Shipmates',\n",
       " 'Skrimshander',\n",
       " 'Smeerenberg',\n",
       " 'Smithfield',\n",
       " 'Snatching',\n",
       " 'Societies',\n",
       " 'Something',\n",
       " 'Sometimes',\n",
       " 'Southerner',\n",
       " 'Sovereign',\n",
       " 'Spaniards',\n",
       " 'Spanishly',\n",
       " 'Specksioneer',\n",
       " 'Specksynder',\n",
       " 'Spermaceti',\n",
       " 'Spermacetti',\n",
       " 'Spitzbergen',\n",
       " 'Spurzheim',\n",
       " 'Stammering',\n",
       " 'Starboard',\n",
       " 'Steelkilt',\n",
       " 'Straightway',\n",
       " 'Strangest',\n",
       " 'Stretched',\n",
       " 'Subtilize',\n",
       " 'Supposing',\n",
       " 'Suppression',\n",
       " 'Suspended',\n",
       " 'Swackhammer',\n",
       " 'TAMBOURINE',\n",
       " 'Tahitians',\n",
       " 'Tamerlane',\n",
       " 'Tartarean',\n",
       " 'Tartarian',\n",
       " 'Temperance',\n",
       " 'Teneriffe',\n",
       " 'Tennessee',\n",
       " 'Testament',\n",
       " 'Therefore',\n",
       " 'Threading',\n",
       " 'Throttling',\n",
       " 'Throughout',\n",
       " 'Thrusting',\n",
       " 'Thundering',\n",
       " 'Tongatobooarrs',\n",
       " 'Tormentoto',\n",
       " 'Trafalgar',\n",
       " 'Tranquilly',\n",
       " 'Transported',\n",
       " 'Tuileries',\n",
       " 'UNPUBLISHED',\n",
       " 'UNWINDING',\n",
       " 'Ultimately',\n",
       " 'Unappalled',\n",
       " 'Uncommonly',\n",
       " 'Unconsciously',\n",
       " 'Unerringly',\n",
       " 'Unfitness',\n",
       " 'Unicornism',\n",
       " 'Unmindful',\n",
       " 'Unobserved',\n",
       " 'Unwittingly',\n",
       " 'Uppermost',\n",
       " 'Valparaiso',\n",
       " 'Vancouver',\n",
       " 'Vehemently',\n",
       " 'Venetianly',\n",
       " 'Vengeance',\n",
       " 'Vermonters',\n",
       " 'Versailles',\n",
       " 'Vineyarder',\n",
       " 'WHALEBONE',\n",
       " 'WHALESHIPS',\n",
       " 'Washington',\n",
       " 'Wellington',\n",
       " 'Whalebone',\n",
       " 'Wheelbarrow',\n",
       " 'Wherefore',\n",
       " 'Whereupon',\n",
       " 'Whirlpooles',\n",
       " 'Whitehall',\n",
       " 'Whiteness',\n",
       " 'Whitsuntide',\n",
       " 'Whosoever',\n",
       " 'Willoughby',\n",
       " 'Winnebago',\n",
       " 'Woebegone',\n",
       " 'Wonderfullest',\n",
       " 'Yorkshire',\n",
       " 'Zealanders',\n",
       " 'Zeuglodon',\n",
       " 'Zoroaster',\n",
       " '_____________',\n",
       " 'abandoned',\n",
       " 'abandonedly',\n",
       " 'abandonment',\n",
       " 'abasement',\n",
       " 'abatement',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abhorrence',\n",
       " 'abhorrent',\n",
       " 'abhorring',\n",
       " 'ablutions',\n",
       " 'abominable',\n",
       " 'abominate',\n",
       " 'abominated',\n",
       " 'abomination',\n",
       " 'aboriginal',\n",
       " 'aboriginally',\n",
       " 'aboriginalness',\n",
       " 'abortions',\n",
       " 'abounding',\n",
       " 'aboundingly',\n",
       " 'absolutely',\n",
       " 'absorbing',\n",
       " 'absorbingly',\n",
       " 'abstained',\n",
       " 'abstemious',\n",
       " 'abstinence',\n",
       " 'abstracted',\n",
       " 'abstraction',\n",
       " 'abundance',\n",
       " 'abundantly',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'accessible',\n",
       " 'accessory',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodation',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniments',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accountable',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulating',\n",
       " 'accurately',\n",
       " 'accustomed',\n",
       " 'acerbities',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquiesce',\n",
       " 'acquiesced',\n",
       " 'acquiescence',\n",
       " 'acridness',\n",
       " 'acuteness',\n",
       " 'additional',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adequately',\n",
       " 'adhesiveness',\n",
       " 'adjoining',\n",
       " 'adjusting',\n",
       " 'admeasurement',\n",
       " 'admeasurements',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admitting',\n",
       " 'admonished',\n",
       " 'admonishing',\n",
       " 'admonitions',\n",
       " 'admonitory',\n",
       " 'adolescence',\n",
       " 'adoration',\n",
       " 'adornment',\n",
       " 'adulterer',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adventurously',\n",
       " 'advertised',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affidavit',\n",
       " 'affinities',\n",
       " 'affirmative',\n",
       " 'afflicted',\n",
       " 'afflictions',\n",
       " 'affording',\n",
       " 'affrighted',\n",
       " 'affrights',\n",
       " 'affronted',\n",
       " 'aforesaid',\n",
       " 'aforethought',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afterwards',\n",
       " 'aggravate',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregation',\n",
       " 'aggregations',\n",
       " 'aggrieved',\n",
       " 'agonizing',\n",
       " 'agonizingly',\n",
       " 'agreeable',\n",
       " 'aimlessly',\n",
       " 'albatross',\n",
       " 'albatrosses',\n",
       " 'allegiance',\n",
       " 'allegorical',\n",
       " 'allowance',\n",
       " 'allowances',\n",
       " 'allurements',\n",
       " 'alluringly',\n",
       " 'allurings',\n",
       " 'allusions',\n",
       " 'alongside',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternating',\n",
       " 'altitudes',\n",
       " 'altogether',\n",
       " 'amazement',\n",
       " 'amazingly',\n",
       " 'ambergris',\n",
       " 'ambiguous',\n",
       " 'ambitious',\n",
       " 'amphibious',\n",
       " 'amphitheatrical',\n",
       " 'amplified',\n",
       " 'amputated',\n",
       " 'amputating',\n",
       " 'amputation',\n",
       " 'amputations',\n",
       " 'anacondas',\n",
       " 'analogical',\n",
       " 'analogies',\n",
       " 'analogous',\n",
       " 'anathemas',\n",
       " 'anatomical',\n",
       " 'ancestors',\n",
       " 'ancestress',\n",
       " 'ancientest',\n",
       " 'angularly',\n",
       " 'animating',\n",
       " 'animation',\n",
       " 'animosity',\n",
       " 'annihilated',\n",
       " 'annihilating',\n",
       " 'annihilation',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annuitants',\n",
       " 'anointing',\n",
       " 'anomalous',\n",
       " 'anomalously',\n",
       " 'anonymous',\n",
       " 'antagonistic',\n",
       " 'antecedent',\n",
       " 'antediluvian',\n",
       " 'antemosaic',\n",
       " 'antichronical',\n",
       " 'anticipated',\n",
       " 'anticipatingly',\n",
       " 'anticipation',\n",
       " 'anticipative',\n",
       " 'antiquities',\n",
       " 'antiquity',\n",
       " 'anxieties',\n",
       " 'apartment',\n",
       " 'apertures',\n",
       " 'apoplectic',\n",
       " 'apostolic',\n",
       " 'apothecary',\n",
       " 'apotheosis',\n",
       " 'appalling',\n",
       " 'appallingly',\n",
       " 'apparatus',\n",
       " 'apparelled',\n",
       " 'apparently',\n",
       " 'apparition',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appearing',\n",
       " 'appellation',\n",
       " 'appellations',\n",
       " 'appellative',\n",
       " 'appendage',\n",
       " 'appetites',\n",
       " 'appliance',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'appointed',\n",
       " 'appointments',\n",
       " 'apportioned',\n",
       " 'appreciative',\n",
       " 'apprehension',\n",
       " 'apprehensions',\n",
       " 'apprehensiveness',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriated',\n",
       " 'approving',\n",
       " 'approvingly',\n",
       " 'approximate',\n",
       " 'aptitudes',\n",
       " 'arbitrary',\n",
       " 'archaeological',\n",
       " 'archaeologists',\n",
       " 'archangel',\n",
       " 'archangelic',\n",
       " 'archangelical',\n",
       " 'archangels',\n",
       " 'archbishopric',\n",
       " 'archiepiscopacy',\n",
       " 'archipelagoes',\n",
       " 'architect',\n",
       " 'architects',\n",
       " 'architecture',\n",
       " 'arguments',\n",
       " 'arithmetic',\n",
       " 'arrangement',\n",
       " 'arranging',\n",
       " 'arrantest',\n",
       " 'arrogance',\n",
       " 'articulated',\n",
       " 'artificial',\n",
       " 'artificially',\n",
       " 'artificialness',\n",
       " 'ascendency',\n",
       " 'ascending',\n",
       " 'ascertained',\n",
       " 'ascertaining',\n",
       " 'ascribable',\n",
       " 'ascriptions',\n",
       " 'aspersion',\n",
       " 'asphaltic',\n",
       " 'aspirations',\n",
       " 'assailable',\n",
       " 'assailant',\n",
       " 'assailants',\n",
       " 'assailing',\n",
       " 'assassins',\n",
       " 'assembled',\n",
       " 'assertion',\n",
       " 'assignment',\n",
       " 'assistance',\n",
       " 'assistants',\n",
       " 'assisting',\n",
       " 'associated',\n",
       " 'associates',\n",
       " 'associations',\n",
       " 'assuaging',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'astonished',\n",
       " 'astonishing',\n",
       " 'astonishment',\n",
       " 'astrological',\n",
       " 'astronomers',\n",
       " 'astronomical',\n",
       " 'atheistical',\n",
       " 'athwartships',\n",
       " 'atmosphere',\n",
       " 'atmospheres',\n",
       " 'atmospheric',\n",
       " 'atrocious',\n",
       " 'attaching',\n",
       " 'attacking',\n",
       " 'attainable',\n",
       " 'attaining',\n",
       " 'attendance',\n",
       " 'attendant',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attentive',\n",
       " 'attentively',\n",
       " 'attenuated',\n",
       " 'attestation',\n",
       " 'attitudes',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attribute',\n",
       " 'audacious',\n",
       " 'augmented',\n",
       " 'authentic',\n",
       " 'authenticated',\n",
       " 'authoritative',\n",
       " 'authoritatively',\n",
       " 'authorities',\n",
       " 'authority',\n",
       " 'authorized',\n",
       " 'automaton',\n",
       " 'auxiliary',\n",
       " 'available',\n",
       " 'avocation',\n",
       " 'awestruck',\n",
       " 'awfulness',\n",
       " 'awkwardness',\n",
       " 'bachelors',\n",
       " 'backbones',\n",
       " 'background',\n",
       " 'backstays',\n",
       " 'backwardly',\n",
       " 'backwards',\n",
       " 'backwoods',\n",
       " 'backwoodsman',\n",
       " 'balancing',\n",
       " 'ballasted',\n",
       " 'bamboozingly',\n",
       " 'bamboozle',\n",
       " 'bannisters',\n",
       " 'banqueter',\n",
       " 'bantering',\n",
       " 'banteringly',\n",
       " 'banterings',\n",
       " 'baptismal',\n",
       " 'barbacued',\n",
       " 'barbarian',\n",
       " 'barbarians',\n",
       " 'barbarous',\n",
       " 'barnacled',\n",
       " 'barometer',\n",
       " 'barreller',\n",
       " 'barricade',\n",
       " 'bartering',\n",
       " 'bashfulness',\n",
       " 'battalions',\n",
       " 'batteries',\n",
       " 'battering',\n",
       " 'beautiful',\n",
       " 'becharmed',\n",
       " 'beckoning',\n",
       " 'bedeadened',\n",
       " 'bedevilling',\n",
       " 'bedfellow',\n",
       " 'bedfellows',\n",
       " 'bedraggled',\n",
       " 'bedsteads',\n",
       " 'beefsteaks',\n",
       " 'befriended',\n",
       " 'befriending',\n",
       " 'beginning',\n",
       " 'beheading',\n",
       " 'beholdest',\n",
       " 'beholding',\n",
       " 'bejuggled',\n",
       " 'believers',\n",
       " 'believing',\n",
       " 'belongest',\n",
       " 'belonging',\n",
       " 'benediction',\n",
       " 'benevolence',\n",
       " 'benevolent',\n",
       " 'benevolently',\n",
       " 'benignity',\n",
       " 'bepatched',\n",
       " 'bequeathed',\n",
       " 'beseeching',\n",
       " 'bespattering',\n",
       " 'bespeaking',\n",
       " 'bestirred',\n",
       " 'bestirring',\n",
       " 'bestreaked',\n",
       " 'bethinking',\n",
       " 'bethought',\n",
       " 'betokened',\n",
       " 'betokening',\n",
       " 'bewildered',\n",
       " 'bewildering',\n",
       " 'bewitched',\n",
       " 'bewitching',\n",
       " 'bilocular',\n",
       " 'birthmark',\n",
       " 'bitterest',\n",
       " 'bitterness',\n",
       " 'bivouacks',\n",
       " 'blackberrying',\n",
       " 'blackened',\n",
       " 'blackling',\n",
       " 'blackness',\n",
       " 'blacksmith',\n",
       " 'blacksmiths',\n",
       " 'blameworthy',\n",
       " 'blandishments',\n",
       " 'blandness',\n",
       " 'blanketing',\n",
       " 'blankness',\n",
       " 'blasphemer',\n",
       " 'blasphemous',\n",
       " 'blasphemy',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Task 5: Control in python\n",
    "# count/display # of tokens in text1 that have more than 8 letters\n",
    "sorted(w for w in set(text1) if len(w)>8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constitution',\n",
       " 'Lion',\n",
       " 'Perception',\n",
       " 'Playstation',\n",
       " 'Question',\n",
       " 'Russion',\n",
       " 'action',\n",
       " 'attention',\n",
       " 'attraction',\n",
       " 'caution',\n",
       " 'cessation',\n",
       " 'condition',\n",
       " 'connection',\n",
       " 'construction',\n",
       " 'conversation',\n",
       " 'conversion',\n",
       " 'correction',\n",
       " 'cusion',\n",
       " 'denomination',\n",
       " 'depression',\n",
       " 'destruction',\n",
       " 'devotion',\n",
       " 'discretion',\n",
       " 'election',\n",
       " 'elevation',\n",
       " 'exception',\n",
       " 'expression',\n",
       " 'fascination',\n",
       " 'impression',\n",
       " 'infection',\n",
       " 'information',\n",
       " 'interruption',\n",
       " 'invention',\n",
       " 'million',\n",
       " 'moderation',\n",
       " 'obsession',\n",
       " 'ontrobution',\n",
       " 'opinion',\n",
       " 'option',\n",
       " 'pension',\n",
       " 'permission',\n",
       " 'petition',\n",
       " 'playstation',\n",
       " 'polllution',\n",
       " 'position',\n",
       " 'question',\n",
       " 'quistion',\n",
       " 'receprion',\n",
       " 'registration',\n",
       " 'relation',\n",
       " 'religion',\n",
       " 'reunion',\n",
       " 'salvation',\n",
       " 'scorpion',\n",
       " 'situation',\n",
       " 'solution',\n",
       " 'subscription',\n",
       " 'tradition']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count/display the tokens in text 5 that end with “ion” \n",
    "sorted(w for w in set(text5) if w.endswith(\"ion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.count('lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5640968673628082"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*text5.count('lol')/len(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in text2 if \"x\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([x for x in text2 if \"x\" in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anxiety',\n",
       " 'Excellent',\n",
       " 'Exchange',\n",
       " 'Excuse',\n",
       " 'Exert',\n",
       " 'Exeter',\n",
       " 'Extend',\n",
       " 'Extravagance',\n",
       " 'Oxford',\n",
       " 'Sussex',\n",
       " 'affixed',\n",
       " 'annexed',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'beaux',\n",
       " 'complexion',\n",
       " 'coxcomb',\n",
       " 'coxcombs',\n",
       " 'exact']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(x for x in text2 if \"x\" in x))[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

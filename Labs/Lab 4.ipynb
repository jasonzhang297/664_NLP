{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qaiqv333WRKl"
   },
   "outputs": [],
   "source": [
    "# Lab: POS tagging in NLTK\n",
    "# This file has small examples that are meant to be run individually\n",
    "#   in the Python shell\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pc6bkkUhWgxb"
   },
   "outputs": [],
   "source": [
    "## Part 1: demo for POS Tagged Corpora in nltk:Brown and Penn Treebank\n",
    "# the Brown corpus has its own set of POS tags\n",
    "\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 275558),\n",
       " ('VERB', 182750),\n",
       " ('.', 147565),\n",
       " ('ADP', 144766),\n",
       " ('DET', 137019),\n",
       " ('ADJ', 83721),\n",
       " ('ADV', 56239),\n",
       " ('PRON', 49334),\n",
       " ('CONJ', 38151),\n",
       " ('PRT', 29829),\n",
       " ('NUM', 14874),\n",
       " ('X', 1386)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_news_tagged = brown.tagged_words(tagset='universal')\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WF79qnczWkP7",
    "outputId": "fa41ccc3-4f94-4097-e636-b439ddd27c24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'),\n",
       "  ('Fulton', 'NP-TL'),\n",
       "  ('County', 'NN-TL'),\n",
       "  ('Grand', 'JJ-TL'),\n",
       "  ('Jury', 'NN-TL'),\n",
       "  ('said', 'VBD'),\n",
       "  ('Friday', 'NR'),\n",
       "  ('an', 'AT'),\n",
       "  ('investigation', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  (\"Atlanta's\", 'NP$'),\n",
       "  ('recent', 'JJ'),\n",
       "  ('primary', 'NN'),\n",
       "  ('election', 'NN'),\n",
       "  ('produced', 'VBD'),\n",
       "  ('``', '``'),\n",
       "  ('no', 'AT'),\n",
       "  ('evidence', 'NN'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('that', 'CS'),\n",
       "  ('any', 'DTI'),\n",
       "  ('irregularities', 'NNS'),\n",
       "  ('took', 'VBD'),\n",
       "  ('place', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('The', 'AT'),\n",
       "  ('jury', 'NN'),\n",
       "  ('further', 'RBR'),\n",
       "  ('said', 'VBD'),\n",
       "  ('in', 'IN'),\n",
       "  ('term-end', 'NN'),\n",
       "  ('presentments', 'NNS'),\n",
       "  ('that', 'CS'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('Executive', 'JJ-TL'),\n",
       "  ('Committee', 'NN-TL'),\n",
       "  (',', ','),\n",
       "  ('which', 'WDT'),\n",
       "  ('had', 'HVD'),\n",
       "  ('over-all', 'JJ'),\n",
       "  ('charge', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  (',', ','),\n",
       "  ('``', '``'),\n",
       "  ('deserves', 'VBZ'),\n",
       "  ('the', 'AT'),\n",
       "  ('praise', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('thanks', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('City', 'NN-TL'),\n",
       "  ('of', 'IN-TL'),\n",
       "  ('Atlanta', 'NP-TL'),\n",
       "  (\"''\", \"''\"),\n",
       "  ('for', 'IN'),\n",
       "  ('the', 'AT'),\n",
       "  ('manner', 'NN'),\n",
       "  ('in', 'IN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('the', 'AT'),\n",
       "  ('election', 'NN'),\n",
       "  ('was', 'BEDZ'),\n",
       "  ('conducted', 'VBN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the tagged_sents function gives POS tagged sentences \n",
    "brown.tagged_sents()[:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAyIWfh5W3rl",
    "outputId": "eab2a603-75d8-401f-fcd0-6f0123fb9f72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'),\n",
       " ('Fulton', 'NP-TL'),\n",
       " ('County', 'NN-TL'),\n",
       " ('Grand', 'JJ-TL'),\n",
       " ('Jury', 'NN-TL'),\n",
       " ('said', 'VBD'),\n",
       " ('Friday', 'NR'),\n",
       " ('an', 'AT'),\n",
       " ('investigation', 'NN'),\n",
       " ('of', 'IN'),\n",
       " (\"Atlanta's\", 'NP$'),\n",
       " ('recent', 'JJ'),\n",
       " ('primary', 'NN'),\n",
       " ('election', 'NN'),\n",
       " ('produced', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('no', 'AT'),\n",
       " ('evidence', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('that', 'CS')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what does this code do? First 20 tokens.\n",
    "brown.tagged_words()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVQM_FhyXJM6",
    "outputId": "fd9e5bb0-6d3b-4c41-81e0-5c42a7fd4a61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The', 'AT')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each tagged word is a pair, which Python calls a tuple  \n",
    "#  it behaves like a list except that you can't change the elements (immutable)\n",
    "wordtag = brown.tagged_words()[0]\n",
    "wordtag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RohOicRXRcA",
    "outputId": "f2eee174-d00c-481c-bc44-cfeae78cb339"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check out the type of wordtag\n",
    "type(wordtag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GwhO1-mCXVlu",
    "outputId": "e77553a0-1871-40ac-8858-d2f271e01a57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can look at the items in the tuple separately by changing the number in the bracket\n",
    "wordtag[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yajWElcXXljW",
    "outputId": "a4363928-9a68-4615-d440-0fbfbf35e8ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the brown corpus can also be accessed by category\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RW5jXH1UXmU6",
    "outputId": "e31e1cbc-78a6-459e-fca0-a17f12404a50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRON'),\n",
       " ('was', 'VERB'),\n",
       " ('among', 'ADP'),\n",
       " ('these', 'DET'),\n",
       " ('that', 'ADP'),\n",
       " ('Hinkle', 'NOUN'),\n",
       " ('identified', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('photograph', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('Barco', 'NOUN'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('For', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('seems', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('Barco', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('fancying', 'VERB')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the category \"humor\" and return the first 20 tokens.\n",
    "brown_humor_tagged = brown.tagged_words(categories='humor', tagset='universal')\n",
    "brown_humor_tagged[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_zSZOf7MYP7K"
   },
   "outputs": [],
   "source": [
    "# Penn treebank\n",
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0XcuaQhYWIb",
    "outputId": "f0e99fd6-70cf-46d0-d99f-fdc7e4d3af6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( (S \n",
      "    (NP-SBJ \n",
      "      (NP (NNP Pierre) (NNP Vinken) )\n",
      "      (, ,) \n",
      "      (ADJP \n",
      "        (NP (CD 61) (NNS years) )\n",
      "        (JJ old) )\n",
      "      (, ,) )\n"
     ]
    }
   ],
   "source": [
    "# use corpus methods to get the text as strings and as tokens as before\n",
    "treebank_text = treebank.raw() # To raw tokens\n",
    "print(treebank_text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5BWXicuYvQI",
    "outputId": "68e32310-bcf3-4c2d-9aaa-6e1048d91054"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Vinken']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treebank also provides tokenization\n",
    "treebank_tokens = treebank.words()\n",
    "treebank_tokens[:20]\n",
    "# look at the words level, return the first 20 tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTVsLesNY7X8",
    "outputId": "9cf0cc68-9dbc-433b-b495-7cb9eeedb034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "#  we also have functions to get words with tags and sentences with tagged words\n",
    "treebank_tagged_words = treebank.tagged_words()\n",
    "print(treebank_tagged_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WeClJimQZDFc",
    "outputId": "1ac926e7-31e3-4a10-a361-a0d007655ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# we can look at the tagging at the sentence level\n",
    "treebank_tagged = treebank.tagged_sents()\n",
    "print(treebank_tagged[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hDGyetNZKhN",
    "outputId": "8acf0bb5-94bf-4d6d-8036-f347380e73fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.', 'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '-NONE-', 'RB', 'TO', 'PRP', 'RBR', 'WDT', 'VBP', 'RP', 'PRP$', 'JJS', 'POS', '``', 'EX', \"''\", 'WP', ':', 'JJR', 'WRB', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS', 'FW', 'UH', 'SYM', 'LS', '#'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Frequency distribution of tags in Penn Treebank\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in treebank.tagged_words())\n",
    "tag_fd.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KWW4O-quZOl2",
    "outputId": "c9b1c8bd-0802-4f11-ba2a-d1e3e9ad97ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 13166\n",
      "IN 9857\n",
      "NNP 9410\n",
      "DT 8165\n",
      "-NONE- 6592\n",
      "NNS 6047\n",
      "JJ 5834\n",
      ", 4886\n",
      ". 3874\n",
      "CD 3546\n",
      "VBD 3043\n",
      "RB 2822\n",
      "VB 2554\n",
      "CC 2265\n",
      "TO 2179\n",
      "VBN 2134\n",
      "VBZ 2125\n",
      "PRP 1716\n",
      "VBG 1460\n",
      "VBP 1321\n",
      "MD 927\n",
      "POS 824\n",
      "PRP$ 766\n",
      "$ 724\n",
      "`` 712\n",
      "'' 694\n",
      ": 563\n",
      "WDT 445\n",
      "JJR 381\n",
      "NNPS 244\n",
      "WP 241\n",
      "RP 216\n",
      "JJS 182\n",
      "WRB 178\n",
      "RBR 136\n",
      "-RRB- 126\n",
      "-LRB- 120\n",
      "EX 88\n",
      "RBS 35\n",
      "PDT 27\n",
      "# 16\n",
      "WP$ 14\n",
      "LS 13\n",
      "FW 4\n",
      "UH 3\n",
      "SYM 1\n"
     ]
    }
   ],
   "source": [
    "# what does this code do?\n",
    "for tag,freq in tag_fd.most_common():\n",
    "    print (tag, freq)\n",
    "# prints out the most common freq in order throught the corpus / Re-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a7swEPVZRmw",
    "outputId": "3cbda990-b6a5-4773-8d0a-aef1d7a3520e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['N', ',', 'C', 'J', 'M', 'V', 'D', 'I', '.', '-', 'R', 'T', 'P', 'W', '`', 'E', \"'\", ':', '$', 'F', 'U', 'S', 'L', '#']) \n",
      "\n",
      "N 28867\n",
      "V 12637\n",
      "I 9857\n",
      "D 8165\n",
      "- 6838\n",
      "J 6397\n",
      "C 5811\n",
      ", 4886\n",
      ". 3874\n",
      "P 3333\n",
      "R 3209\n",
      "T 2179\n",
      "M 927\n",
      "W 878\n",
      "$ 724\n",
      "` 712\n",
      "' 694\n",
      ": 563\n",
      "E 88\n",
      "# 16\n",
      "L 13\n",
      "F 4\n",
      "U 3\n",
      "S 1\n"
     ]
    }
   ],
   "source": [
    "# use the first letter of the POS tag to get classes of tags\n",
    "tag_classes_fd = nltk.FreqDist(tag[0] for (word, tag) in treebank.tagged_words())\n",
    "print(tag_classes_fd.keys(), '\\n') # only shows the first letter\n",
    "for tag,freq in tag_classes_fd.most_common():\n",
    "    print (tag, freq)\n",
    "# re-rank the most common one in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l2ZK3jtZmUT"
   },
   "source": [
    "## Part 2: POS Tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1tNaTdqZrGS",
    "outputId": "d3eae5f9-78a2-41b9-8428-dca15559b066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3522"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the data into training and test data:90% for training data\n",
    "size = int(len(treebank_tagged) * 0.9)\n",
    "treebank_train = treebank_tagged[:size]\n",
    "treebank_test = treebank_tagged[size:]\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQX7oFNZZxPl",
    "outputId": "b1967282-9b72-44c6-e2ba-71eeaa2973ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NN'), ('Vinken', 'NN'), (',', 'NN'), ('61', 'NN'), ('years', 'NN'), ('old', 'NN'), (',', 'NN'), ('will', 'NN'), ('join', 'NN'), ('the', 'NN'), ('board', 'NN'), ('as', 'NN'), ('a', 'NN'), ('nonexecutive', 'NN'), ('director', 'NN'), ('Nov.', 'NN'), ('29', 'NN'), ('.', 'NN'), ('Mr.', 'NN'), ('Vinken', 'NN'), ('is', 'NN'), ('chairman', 'NN'), ('of', 'NN'), ('Elsevier', 'NN'), ('N.V.', 'NN'), (',', 'NN'), ('the', 'NN'), ('Dutch', 'NN'), ('publishing', 'NN'), ('group', 'NN'), ('.', 'NN'), ('Rudolph', 'NN'), ('Agnew', 'NN'), (',', 'NN'), ('55', 'NN'), ('years', 'NN'), ('old', 'NN'), ('and', 'NN'), ('former', 'NN'), ('chairman', 'NN'), ('of', 'NN'), ('Consolidated', 'NN'), ('Gold', 'NN'), ('Fields', 'NN'), ('PLC', 'NN'), (',', 'NN'), ('was', 'NN'), ('named', 'NN'), ('*-1', 'NN'), ('a', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Default Tagger assign 'NN' to every word\n",
    "# creates the tagger\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "# show the effect of the tagger by tagging the first 50 words\n",
    "print(t0.tag(treebank_tokens[:50]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Evyk7Gh5Z_Gc",
    "outputId": "499143fb-ee84-45fd-a859-570c9ddeb077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14697201017811704\n"
     ]
    }
   ],
   "source": [
    "# evaluate function applies the tagger t0 to the untagged version of treebank\n",
    "#   and compares with the tagged version\n",
    "print(t0.accuracy(treebank_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OQReJk5aPt0"
   },
   "source": [
    "## Part 3: n-gram tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eT_if6eHaSto"
   },
   "outputs": [],
   "source": [
    "# Unigram tagger learns tag with the highest probability for each word\n",
    "# creates the tagger on the training set\n",
    "t1 = nltk.UnigramTagger(treebank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAOvTQRDaV8R",
    "outputId": "7d0afee3-ef76-4724-de52-3805478aa04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "# show the effect of the tagger by tagging the first 20 words\n",
    "print(t1.tag(treebank_tokens[:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVgSDcMLaeLS",
    "outputId": "90486bdc-0d24-4fd4-bdcc-fa29c68267a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627989821882952"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluates the tagger on the test set\n",
    "t1.accuracy(treebank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fw8nk5QRaqJj"
   },
   "outputs": [],
   "source": [
    "# Bigram Tagging with Backoff to Combine Taggers\n",
    "# create a sequence of taggers with backoff to get a bigram tagger\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(treebank_train, backoff=t0)\n",
    "t2 = nltk.BigramTagger(treebank_train, backoff=t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XoukCI1SatSa",
    "outputId": "ead2412c-6046-42c8-f49f-67745bd87d33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905852417302799"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy with BigramTagger: \n",
    "t2.accuracy(treebank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "igjeKjIkavct"
   },
   "outputs": [],
   "source": [
    "# Task: Using the bigram tagger on some new text\n",
    "text = \"Three Calgarians have found a rather unusual way of leaving snow and ice behind. They set off this week on foot and by camels on a grueling trek across the burning Arabian desert.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_BDq8Blay1x",
    "outputId": "cd9f014c-50b1-415c-de1b-c66d507b0c01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Three Calgarians have found a rather unusual way of leaving snow and ice behind.', 'They set off this week on foot and by camels on a grueling trek across the burning Arabian desert.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# step1: we should separate the text into sentences \n",
    "textsplit = nltk.sent_tokenize(text)\n",
    "print(textsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wtSXtxla87B",
    "outputId": "93203ffc-4ec9-4cd2-c300-57af32bf6764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Three', 'Calgarians', 'have', 'found', 'a', 'rather', 'unusual', 'way', 'of', 'leaving', 'snow', 'and', 'ice', 'behind', '.'], ['They', 'set', 'off', 'this', 'week', 'on', 'foot', 'and', 'by', 'camels', 'on', 'a', 'grueling', 'trek', 'across', 'the', 'burning', 'Arabian', 'desert', '.']]\n"
     ]
    }
   ],
   "source": [
    "# step 2: apply the word tokenizer to each sentence\n",
    "tokentext = [nltk.word_tokenize(sent) for sent in textsplit]\n",
    "print(tokentext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VL1uBYAGbLmp",
    "outputId": "bc8b74dc-037d-4fd4-c063-92854cacc4fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Three', 'CD'), ('Calgarians', 'NN'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'IN'), ('.', '.')], [('They', 'PRP'), ('set', 'VBN'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NN'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'NN'), ('desert', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# step 3: use the t2 bigram tagger to tag each sentence tokens\n",
    "taggedtext = [t2.tag(tokens) for tokens in tokentext]\n",
    "print(taggedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnVQ8J70bXGm",
    "outputId": "3400f498-e8d0-4101-c34c-c864a83fb8d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Three', 'CD'), ('Calgarians', 'NNPS'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'NN'), ('.', '.')], [('They', 'PRP'), ('set', 'VBD'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NNS'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'JJ'), ('desert', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# different tagger: use the Stanford POS tagger to tag each sentence tokens\n",
    "taggedtextStanford = [nltk.pos_tag(tokens) for tokens in tokentext]\n",
    "print(taggedtextStanford)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
